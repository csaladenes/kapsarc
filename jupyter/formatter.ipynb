{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Included installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install influxdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from influxdb import DataFrameClient\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "purge=False\n",
    "write_out=True\n",
    "full_overwrite=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish DB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'admin'\n",
    "password = open('auth/influxa.txt','r').read()\n",
    "host='influxdb'\n",
    "port=8086\n",
    "dbname='base'\n",
    "protocol = 'line' #'json'\n",
    "client = DataFrameClient(host, port, user, password, dbname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if purge:\n",
    "    client.drop_database(dbname)\n",
    "    client.drop_retention_policy(dbname)\n",
    "    client.create_database(dbname)\n",
    "    client.create_retention_policy(dbname, '3300d', 1, default=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlipath='../html/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "grafana = \"http://grafana:3000/\"\n",
    "headers = {\n",
    "    'Authorization': 'Bearer '+open('auth/grafana.txt','r').read(),\n",
    "    'Accept': 'application/json',\n",
    "    'Content-Type': 'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(grafana+'api/folders', headers=headers)\n",
    "folders=json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pytz\n",
    "utc=pytz.UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push2influx(df,measurement,field_columns,tag_columns,shift=False,dbclient=client,wo=write_out,fo=full_overwrite,daily=True):\n",
    "    if wo:\n",
    "        df=df.sort_index()\n",
    "        df.index=df.index.tz_localize('GMT')\n",
    "        if shift:\n",
    "            df.index+=pd.to_timedelta('12h')\n",
    "        if fo: \n",
    "            print('Purging',measurement,'...')\n",
    "            dbclient.query('DROP MEASUREMENT '+measurement)\n",
    "        else:\n",
    "            latest=dbclient.query('SELECT * FROM '+measurement+' GROUP BY \"1d\" ORDER BY DESC LIMIT 1')\n",
    "            if latest:\n",
    "                lat=latest[list(latest.keys())[0]].index[0]\n",
    "                if daily: lat+=pd.to_timedelta('1d')\n",
    "                df=df[lat:]\n",
    "                print('Slicing',measurement,'from',lat,'...')\n",
    "            else:\n",
    "                print('No data in db for',measurement,'...')\n",
    "        time.sleep(3)\n",
    "        print('Writing to',measurement,'...')\n",
    "        bsize=5000\n",
    "        bwait=2\n",
    "        print(len(df),'data points will be written in',len(df)/bsize,'batches.')\n",
    "        print('Expected query running time is:',int((len(df)/bsize)*bwait*1.1)+3,'seconds.')\n",
    "        for i in range(int(len(df)/bsize)+1):\n",
    "            r=range(i*bsize,min(len(df),(i+1)*bsize))\n",
    "            dc=df.iloc[r]\n",
    "            print('Writing batch',i+1,'...')\n",
    "            dbclient.write_points(dc, measurement, protocol=protocol,\n",
    "                                field_columns=field_columns,\n",
    "                                tag_columns=[])\n",
    "            time.sleep(bwait)\n",
    "        time.sleep(3)\n",
    "        print('Done!')\n",
    "    else:\n",
    "        print('Write-out not enabled. Skipping...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch stock names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"https://api.iextrading.com/1.0/ref-data/symbols\"\n",
    "result = requests.get(url).json()\n",
    "tickers=pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas_ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_ta as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('3189 days 10:57:14.440091')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('../data/all_stocks_5yr.csv')\n",
    "df['date']=df['date'].astype(np.datetime64)\n",
    "pd.to_datetime('now')-df['date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-02-08</th>\n",
       "      <td>15.07</td>\n",
       "      <td>15.12</td>\n",
       "      <td>14.63</td>\n",
       "      <td>14.75</td>\n",
       "      <td>8407500</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-11</th>\n",
       "      <td>14.89</td>\n",
       "      <td>15.01</td>\n",
       "      <td>14.26</td>\n",
       "      <td>14.46</td>\n",
       "      <td>8882000</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-12</th>\n",
       "      <td>14.45</td>\n",
       "      <td>14.51</td>\n",
       "      <td>14.10</td>\n",
       "      <td>14.27</td>\n",
       "      <td>8126000</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-13</th>\n",
       "      <td>14.30</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.25</td>\n",
       "      <td>14.66</td>\n",
       "      <td>10259500</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-14</th>\n",
       "      <td>14.94</td>\n",
       "      <td>14.96</td>\n",
       "      <td>13.16</td>\n",
       "      <td>13.99</td>\n",
       "      <td>31879900</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             open   high    low  close    volume Name\n",
       "date                                                 \n",
       "2013-02-08  15.07  15.12  14.63  14.75   8407500  AAL\n",
       "2013-02-11  14.89  15.01  14.26  14.46   8882000  AAL\n",
       "2013-02-12  14.45  14.51  14.10  14.27   8126000  AAL\n",
       "2013-02-13  14.30  14.94  14.25  14.66  10259500  AAL\n",
       "2013-02-14  14.94  14.96  13.16  13.99  31879900  AAL"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.set_index('date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stack=df.reset_index().set_index(['Name','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs=[]\n",
    "# for i in df_stack.index.get_level_values(0).unique():\n",
    "for i in ['AAL', 'AAPL']:\n",
    "    try:\n",
    "        dfa=df_stack.loc[i]\n",
    "        dfa.ta.macd(close='close', fast=12, slow=26, signal=9, append=True)\n",
    "        dfa.ta.bbands(20,append=True)\n",
    "        dfa['ticker']=i\n",
    "        \n",
    "        dfa[\"Diff\"] = dfa.close.diff()\n",
    "        dfa[\"SMA_2\"] = dfa.close.rolling(2).mean()\n",
    "        dfa[\"Force_Index\"] = dfa.close * dfa.volume\n",
    "        dfa[\"y\"] = dfa[\"Diff\"].apply(lambda x: 1 if x > 0 else 0).shift(-1)\n",
    "        dfb = dfa[['SMA_2','Force_Index','y']].dropna()\n",
    "\n",
    "        X = dfb.drop([\"y\"], axis=1).values\n",
    "        y = dfb[\"y\"].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "           X,\n",
    "           y,\n",
    "           test_size=0.2,\n",
    "           shuffle=False,\n",
    "        )\n",
    "        clf = make_pipeline(StandardScaler(), MLPClassifier(random_state=0, shuffle=False))\n",
    "        clf.fit(\n",
    "           X_train,\n",
    "           y_train,\n",
    "        )\n",
    "        y_pred = clf.predict(X_test)\n",
    "        dfa['mlp']=y_pred[-1]\n",
    "        \n",
    "        dfs.append(dfa)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dfs.join(tickers.set_index('symbol')['name'],on='ticker')\n",
    "df['name']=df['name'].str.replace(' INC','').str.title()\n",
    "\n",
    "df['diff']=df['close']-df['open']\n",
    "direction=[]\n",
    "for i in df['diff'].values:\n",
    "    if i<0:\n",
    "        direction.append('minus')\n",
    "    else:\n",
    "        direction.append('plus')\n",
    "df['direction']=direction\n",
    "df['diff']=abs(df['diff'])\n",
    "\n",
    "direction=[]\n",
    "for i in df['MACDh_12_26_9'].values:\n",
    "    if i<0:\n",
    "        direction.append('minus')\n",
    "    else:\n",
    "        direction.append('plus')\n",
    "df['MACDh_direction']=direction\n",
    "\n",
    "df['bollingerm']=df['close']-df['BBM_20_2.0']\n",
    "df['bollingeru']=df['close']-df['BBU_20_2.0']\n",
    "df['bollingerl']=df['close']-df['BBL_20_2.0']\n",
    "direction=[]\n",
    "for i in df[['bollingerm','bollingeru','bollingerl']].values:\n",
    "    if i[0]>0.1:\n",
    "        if i[1]>0:\n",
    "            direction.append(-1)\n",
    "        else:\n",
    "            direction.append(-0.5)\n",
    "    elif i[0]<-0.1:\n",
    "        if i[2]>0:\n",
    "            direction.append(0.5)\n",
    "        else:\n",
    "            direction.append(1)\n",
    "    else:\n",
    "        direction.append(0)\n",
    "df['bollinger']=direction\n",
    "\n",
    "df['overall']=df['bollinger']+(df['mlp']-0.5)*2+df['MACDh_12_26_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[df['ticker'].isin(['AAPL','AAL'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push to Influx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purging daily ...\n",
      "Writing to daily ...\n",
      "2518 data points will be written in 0.5036 batches.\n",
      "Expected query running time is: 4 seconds.\n",
      "Writing batch 1 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "tag_columns=['name','direction','ticker','MACDh_direction']\n",
    "field_columns=[i for i in df.columns if i not in tag_columns]\n",
    "measurement='daily'\n",
    "push2influx(df1,measurement,field_columns,tag_columns,fo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn keras pandas_datareader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 3s 12ms/step - loss: 0.6959 - acc: 0.5154\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6953 - acc: 0.5134\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6948 - acc: 0.5134\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6946 - acc: 0.5154\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6942 - acc: 0.5045\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.6940 - acc: 0.5075\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6938 - acc: 0.5085\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.6937 - acc: 0.5134\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6936 - acc: 0.5095\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6935 - acc: 0.5095\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6934 - acc: 0.5065\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6933 - acc: 0.5104\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.6933 - acc: 0.5085\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6932 - acc: 0.5085\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6932 - acc: 0.5095\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.6931 - acc: 0.5144\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6931 - acc: 0.5164\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6930 - acc: 0.5124\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6931 - acc: 0.5124\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6929 - acc: 0.5114\n",
      "0.5357142857142857\n"
     ]
    }
   ],
   "source": [
    "# https://10mohi6.medium.com/super-easy-python-stock-price-forecast-using-keras-lstm-deep-learning-bd972bcca70\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import pandas_datareader as pdr\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dfa=df_stack.loc[i]\n",
    "dfa[\"Diff\"] = dfa.close.diff()\n",
    "dfa[\"SMA_2\"] = dfa.close.rolling(2).mean()\n",
    "dfa[\"Force_Index\"] = dfa.close * dfa.volume\n",
    "dfa[\"y\"] = dfa[\"Diff\"].apply(lambda x: 1 if x > 0 else 0).shift(-1)\n",
    "dfa = dfa[['SMA_2','Force_Index','y']].dropna()\n",
    "X = StandardScaler().fit_transform(dfa.drop([\"y\"], axis=1))\n",
    "y = dfa[\"y\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X,\n",
    "   y,\n",
    "   test_size=0.2,\n",
    "   shuffle=False,\n",
    ")\n",
    "model = Sequential()\n",
    "model.add(LSTM(2, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model.fit(X_train[:, :, np.newaxis], y_train, epochs=20)\n",
    "y_pred = model.predict(X_test[:, :, np.newaxis])\n",
    "print(accuracy_score(y_test, y_pred > 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5357142857142857\n"
     ]
    }
   ],
   "source": [
    "# https://10mohi6.medium.com/super-easy-python-stock-price-forecasting-using-multilayer-perceptron-machine-learning-4f1d1ef9650\n",
    "import pandas_datareader as pdr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dfa=df_stack.loc[i]\n",
    "dfa[\"Diff\"] = dfa.close.diff()\n",
    "dfa[\"SMA_2\"] = dfa.close.rolling(2).mean()\n",
    "dfa[\"Force_Index\"] = dfa.close * dfa.volume\n",
    "dfa[\"y\"] = dfa[\"Diff\"].apply(lambda x: 1 if x > 0 else 0).shift(-1)\n",
    "dfa = dfa[['SMA_2','Force_Index','y']].dropna()\n",
    "\n",
    "X = dfa.drop([\"y\"], axis=1).values\n",
    "y = dfa[\"y\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X,\n",
    "   y,\n",
    "   test_size=0.2,\n",
    "   shuffle=False,\n",
    ")\n",
    "clf = make_pipeline(StandardScaler(), MLPClassifier(random_state=0, shuffle=False))\n",
    "clf.fit(\n",
    "   X_train,\n",
    "   y_train,\n",
    ")\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 4s 13ms/step - loss: 0.6960 - acc: 0.5194\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6955 - acc: 0.5294\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6948 - acc: 0.5264\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.6945 - acc: 0.5284\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6941 - acc: 0.5254\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6938 - acc: 0.5264\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6936 - acc: 0.5234\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6935 - acc: 0.5254\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6933 - acc: 0.5234\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6931 - acc: 0.5264\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6930 - acc: 0.5224\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.6930 - acc: 0.5224\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6928 - acc: 0.5234\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6928 - acc: 0.5234\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6927 - acc: 0.5214\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6926 - acc: 0.5244\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.6926 - acc: 0.5234\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6925 - acc: 0.5224\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6924 - acc: 0.5174\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6924 - acc: 0.5184\n",
      "0.49603174603174605\n"
     ]
    }
   ],
   "source": [
    "# https://10mohi6.medium.com/super-easy-python-stock-price-forecast-using-keras-gru-deep-learning-a85dddce54db\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, GRU\n",
    "import pandas_datareader as pdr\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dfa=df_stack.loc[i]\n",
    "dfa[\"Diff\"] = dfa.close.diff()\n",
    "dfa[\"SMA_2\"] = dfa.close.rolling(2).mean()\n",
    "dfa[\"Force_Index\"] = dfa.close * dfa.volume\n",
    "dfa[\"y\"] = dfa[\"Diff\"].apply(lambda x: 1 if x > 0 else 0).shift(-1)\n",
    "dfa = dfa[['SMA_2','Force_Index','y']].dropna()\n",
    "\n",
    "X = StandardScaler().fit_transform(dfa.drop([\"y\"], axis=1))\n",
    "y = dfa[\"y\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    shuffle=False,\n",
    ")\n",
    "model = Sequential()\n",
    "model.add(GRU(2, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model.fit(X_train[:, :, np.newaxis], y_train, epochs=20)\n",
    "y_pred = model.predict(X_test[:, :, np.newaxis])\n",
    "print(accuracy_score(y_test, y_pred > 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample 7d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=[]\n",
    "# for i in df_stack.index.get_level_values(0).unique():\n",
    "for i in ['AAL', 'AAPL']:\n",
    "    try:\n",
    "        dfa=df_stack.loc[i][['open','close','high','low','volume']]\n",
    "        dfa['open']=dfa.interpolate().resample('7d').first()['open']\n",
    "        dfa['close']=dfa.interpolate().resample('7d').last()['close']\n",
    "        dfa['high']=dfa.interpolate().resample('7d').max()['high']\n",
    "        dfa['low']=dfa.interpolate().resample('7d').min()['low']\n",
    "        dfa['volume']=dfa.interpolate().resample('7d').sum()['volume']\n",
    "        dfa=dfa.dropna()\n",
    "        dfa.ta.macd(close='close', fast=12, slow=26, signal=9, append=True)\n",
    "        dfa.ta.bbands(20,append=True)\n",
    "        dfa['ticker']=i\n",
    "        dfs.append(dfa)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dfs.join(tickers.set_index('symbol')['name'],on='ticker')\n",
    "df['name']=df['name'].str.replace(' INC','').str.title()\n",
    "\n",
    "df['diff']=df['close']-df['open']\n",
    "direction=[]\n",
    "for i in df['diff'].values:\n",
    "    if i<0:\n",
    "        direction.append('minus')\n",
    "    else:\n",
    "        direction.append('plus')\n",
    "df['direction']=direction\n",
    "df['diff']=abs(df['diff'])\n",
    "\n",
    "direction=[]\n",
    "for i in df['MACDh_12_26_9'].values:\n",
    "    if i<0:\n",
    "        direction.append('minus')\n",
    "    else:\n",
    "        direction.append('plus')\n",
    "df['MACDh_direction']=direction\n",
    "\n",
    "df['bollingerm']=df['close']-df['BBM_20_2.0']\n",
    "df['bollingeru']=df['close']-df['BBU_20_2.0']\n",
    "df['bollingerl']=df['close']-df['BBL_20_2.0']\n",
    "direction=[]\n",
    "for i in df[['bollingerm','bollingeru','bollingerl']].values:\n",
    "    if i[0]>0.1:\n",
    "        if i[1]>0:\n",
    "            direction.append(-1)\n",
    "        else:\n",
    "            direction.append(-0.5)\n",
    "    elif i[0]<-0.1:\n",
    "        if i[2]>0:\n",
    "            direction.append(0.5)\n",
    "        else:\n",
    "            direction.append(1)\n",
    "    else:\n",
    "        direction.append(0)\n",
    "df['bollinger']=direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[df['ticker'].isin(['AAPL','AAL'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purging weekly ...\n",
      "Writing to weekly ...\n",
      "504 data points will be written in 0.1008 batches.\n",
      "Expected query running time is: 3 seconds.\n",
      "Writing batch 1 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "tag_columns=['name','direction','ticker','MACDh_direction']\n",
    "field_columns=[i for i in df.columns if i not in tag_columns]\n",
    "measurement='weekly'\n",
    "push2influx(df1,measurement,field_columns,tag_columns,fo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample 1 month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=[]\n",
    "# for i in df_stack.index.get_level_values(0).unique():\n",
    "for i in ['AAL', 'AAPL']:\n",
    "    try:\n",
    "        dfa=df_stack.loc[i][['open','close','high','low','volume']]\n",
    "        dfa['open']=dfa.interpolate().resample('1M').first()['open']\n",
    "        dfa['close']=dfa.interpolate().resample('1M').last()['close']\n",
    "        dfa['high']=dfa.interpolate().resample('1M').max()['high']\n",
    "        dfa['low']=dfa.interpolate().resample('1M').min()['low']\n",
    "        dfa['volume']=dfa.interpolate().resample('1M').sum()['volume']\n",
    "        dfa=dfa.dropna()\n",
    "        dfa.ta.macd(close='close', fast=12, slow=26, signal=9, append=True)\n",
    "        dfa.ta.bbands(20,append=True)\n",
    "        dfa['ticker']=i\n",
    "        dfs.append(dfa)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dfs.join(tickers.set_index('symbol')['name'],on='ticker')\n",
    "df['name']=df['name'].str.replace(' INC','').str.title()\n",
    "\n",
    "df['diff']=df['close']-df['open']\n",
    "direction=[]\n",
    "for i in df['diff'].values:\n",
    "    if i<0:\n",
    "        direction.append('minus')\n",
    "    else:\n",
    "        direction.append('plus')\n",
    "df['direction']=direction\n",
    "df['diff']=abs(df['diff'])\n",
    "\n",
    "direction=[]\n",
    "for i in df['MACDh_12_26_9'].values:\n",
    "    if i<0:\n",
    "        direction.append('minus')\n",
    "    else:\n",
    "        direction.append('plus')\n",
    "df['MACDh_direction']=direction\n",
    "\n",
    "df['bollingerm']=df['close']-df['BBM_20_2.0']\n",
    "df['bollingeru']=df['close']-df['BBU_20_2.0']\n",
    "df['bollingerl']=df['close']-df['BBL_20_2.0']\n",
    "direction=[]\n",
    "for i in df[['bollingerm','bollingeru','bollingerl']].values:\n",
    "    if i[0]>0.1:\n",
    "        if i[1]>0:\n",
    "            direction.append(-1)\n",
    "        else:\n",
    "            direction.append(-0.5)\n",
    "    elif i[0]<-0.1:\n",
    "        if i[2]>0:\n",
    "            direction.append(0.5)\n",
    "        else:\n",
    "            direction.append(1)\n",
    "    else:\n",
    "        direction.append(0)\n",
    "df['bollinger']=direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[df['ticker'].isin(['AAPL','AAL'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purging monthly ...\n",
      "Writing to monthly ...\n",
      "84 data points will be written in 0.0168 batches.\n",
      "Expected query running time is: 3 seconds.\n",
      "Writing batch 1 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "tag_columns=['name','direction','ticker','MACDh_direction']\n",
    "field_columns=[i for i in df.columns if i not in tag_columns]\n",
    "measurement='monthly'\n",
    "push2influx(df1,measurement,field_columns,tag_columns,fo=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
